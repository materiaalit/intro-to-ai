---
  title: Part 1
  exercise_page: true
  quiz_page: false
  published: true
---


You can find the lecture slides for this part on the <a href="https://studies.helsinki.fi/courses/cur/hy-opt-cur-2021-3a70433a-d793-46a4-a43e-a42968419133">course homepage</a>
under Materials.

<% partial 'partials/material_heading' do %>
  What is AI?
<% end %>

<p>
  In this first part, we will discuss what we mean when we talk about AI.
  It turns out that there is no exact definition at all, but that the
  field is rather being redefined at all times.
</p>

<p>
  We will also briefly discuss the philosophical aspects of AI: whether
  intelligent behavior implies or requires the existence of a ''mind'', and
  in what extent is consciousness replicable as a computational process.
  However, this course is first and foremost focused on building
  practically useful AI tools, and we will quickly push considerations
  about consciousness aside as they tend to be only in the way when
  designing working solutions to real problems.
</p>

<p>
  The first technical topic, also covered in Part 1, is
  problem-solving by search.
</p>

<% partial 'partials/hint', locals: { name: 'Learning objectives of Part 1' } do %>

<table class="table">
  <tr>
    <th>
      Theme
    </th>
    <th>
      Objectives (after the course, you ...)
    </th>
  </tr>
  <tr>
    <td>
      Philosophy and history of AI
    </td>
    <td>
      <ul>
	<li>can express the basic philosophical problems related to AI
(the difficulty in defining AI and consciousness, acting vs thinking,
Turing test)
	<li>can distinguish between realistic and unrealistic AI in
science-fiction
	<li>can describe the contrast between "Good Old Fashioned
AI" (GOFAI) and modern AI approaches
	<li>know the main-stream developments in the history of AI
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      Games and search (will be continued)
    </td>
    <td>
      <ul>
	<li>can formulate a problem as a graph and apply search algorithms to solve it
	<li>can explain and implement A* search
	<li>can formulate a simple game (such as tic-tac-toe) as a game tree
	<li>can explain and implement the minimax algorithm and depth-limited alpha-beta pruning
	<li>can design a reasonable heuristic evaluation function in a game (e.g., chess)
      </ul>
    </td>
  </tr>
</table>

<% end %>


<% partial 'partials/material_sub_heading' do %>
  A (Very) Brief History of AI
<% end %>

<p>
  Artificial Intelligence (AI) is a subdiscipline of Computer
  Science. Indeed, it is arguably as old as Computer Science itself:
  <a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a>
  (1912-1954) proposed the Turing machine -- the formal model
  underlying the theory of computation -- as a model with equivalent
  capacity to carry out calculations as a human being (ignoring
  resource constraints on either side).
</p>

<p>
  Contrary to common belief, the term AI was <b>not</b> originally
  proposed by John McCarthy (1927-2011) -- often referred to as the
  Father of AI. However, McCarthy soon accepted its use and it became
  the established term when McCarthy used it in the title of a summer
  seminar, known
  as <a href="https://en.wikipedia.org/wiki/Dartmouth_workshop">
  Dartmouth conference</a> held in 1956 at Dartmouth College.
</p>

<p>
  As computers developed to the level where it was feasible to
  experiment with practical AI algorithms in the 1940s and 1950s, the most
  distinctive AI problems were games. Games provided a convenient
  restricted domain that could be formalized easily. Board games such
  as checkers, chess, and (recently quite prominently) Go, have
  inspired countless researchers,  and continue to do so.
</p>

<p>
  Closely related to games, search and planning algorithms were an
  area where AI lead to great advances in the 1960s: in a little
  while, we will be able to admire the beauty of, for example,
  the <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">A*
  search algorithm</a> and
  <a href="https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning">alpha-beta
  pruning</a>, and apply them to solve AI problems.</p>

<% partial 'partials/hint', locals: { name: 'The Elusive Definition of AI' } do %>

<p>
  There's an old (geeky) joke that AI is defined as ''cool things that
  computer can't do.'' The joke is that under this definition, AI can
  never make any progress: as soon as we find a way to do something cool
  with a computer, it stops being an AI problem.
</p>

<p>
  However, there is an element of truth in the definition in the sense
  that fifty years ago, for instance, search and planning algorithms
  were considered to belong to the domain of AI. Nowadays algorithms
  such as breadth-first and depth-first search, and A*, are thought
  (and taught) as belonging to Data Structures and Algorithms.
</p>

<% end %>

<p>
  The history of AI, just like many other fields of science, has
  witnessed the coming and going (and coming back and going again,
  etc.) of various different paradigms. Typically, a particular
  paradigm is adopted by most of the research community and
  ultra-optimistic estimates of progress in the near-future are
  provided. All such scenarios so far have ended up running into
  unsurmountable, unexpected problems and the interest has died
  out. For example, in the 1960s <b>artificial neural networks</b>
  were widely believed to solve all AI problems by imitating the
  learning mechanisms in the nature (such as the human central nervous
  system and the brain, in particular). However, certain negative
  results about the expressibility of certain neural computation
  models quickly lead to pessimism and an <b>AI winter</b> followed.
</p>

<p>
  The 1980s brought a new wave of AI methods based on logic-based
  methods. So called <b>expert systems</b>, manipulating knowledge
  elicited from domain experts, such as medical doctors, showed
  great promise by solving nicely contained, well-defined
  ''toy problems'', but turned out to fail every time when they
  were deployed in more complex, real-world problems. The second
  (or the third, depending on the counting) AI winter lasted from the
  late 1980s until the mid-1990s.
</p>

<p>
  Currently, since the turn of the millennium, AI has been on the rise
  again. In the late 1990s, the ''classical'' or <b>''Good
  Old-Fashioned AI'' (GOFAI)</b> that addressed crisp, clearly
  defined, and isolated problems begun to be replaced by so called
  <b>''modern AI''</b> (in lack of a better name). Modern AI
  introduced methods that were able to handle uncertain and imprecise
  information, most notably by probabilistic methods, and which had
  the great advantage that it was designed to work in the real world.
  The rise of modern AI has continued until present day, further
  boosted by the come-back of neural networks under the label <b>Deep
  Learning</b>.
</p>

<p>
  Whether the history will repeat itself, and the current boom will be
  once again followed by an AI winter, is a matter that only time can
  tell. Even if it does, the significance of AI in the society is
  going to stay. Today, we live our life surrounded by AI, most of the
  time happily unaware of it: the music that we listen, the products
  that we buy online, the movies and series that we watch, our routes
  of transportation, and the information that we have available, are
  all influenced more and more by AI.
</p>

<p>
  No wonder that you have decided to learn more about AI!
</p>

<p> Being able to apply AI methods and thus to be part of the progress
  of AI is a great way to change the world for the better. And even if
  you wouldn't aspire to become an AI researcher or developer, it is
  almost your duty as a citizen to understand at least the
  fundamentals of AI so that you can better use it: be aware of its
  limitations and enjoy all the goodies it can provide.
</p>

<% partial 'partials/material_sub_heading' do %>
  On the Philosophy of AI
<% end %>



<p>
  The best known contribution to AI by Turing is his <i>imitation
  game</i>, which later became known as the <a href="https://en.wikipedia.org/wiki/Turing_test">Turing test</a>.  In the
  test, a human interrogator interacts with two players, A and B, by
  exchanging written messages (in a ''chat''). If the interrogator
  cannot determine which player, A or B, is a computer and which is a
  human, the computer is said to pass the test.  The argument is that
  if a computer is indistinguishable from a human in a general
  natural language conversation, then it must have reached human-level
  intelligence.
</p>

<p>
  Turing's argument that whether a being is intelligent or not can be
  decided based on the behavior it exhibits has been challenged by
  some. The best known counter-argument is John Searle's
  <a href="http://www.iep.utm.edu/chineser/">Chinese Room</a> thought
  experiment. Searle descibes an experiment where a person who doesn't
  know Chinese is locked in a room. Outside the room is a person who
  can slip notes written in Chinese inside the room through a mail
  slot. The person inside the room is given a large manual where she
  can find detailed instructions for responding to the notes she
  receives from the outside.
</p>

<p>
  Searle argued that that even if the person outside the room gets the
  impression that he is in a conversation with another
  Chinese-speaking person, the person inside the room does <i>not
  understand</i> Chinese. Likewise, his argument continues, even if a
  machine behaves in an intelligent manner, for example, by
  passing the Turing test, it doesn't follow that it <i>is</i>
  intelligent or that it has a ''mind'' in the way that a human
  has. The word ''intelligent'' can also be replaced by the word
  ''self-conscious'' and a similar argument can be made.
</p>

<p>
  The definition of intelligence, natural or artificial, and
  consciousness appears to be extremely evasive and leads to
  apparently never-ending discourse. In an intellectual company, with
  plenty of good Burgundy (Bordeaux will also do), this discussion can
  be quite enjoyable. However, as John
  McCarthy <a href="http://www-formal.stanford.edu/jmc/aiphil/node2.html#SECTION00020000000000000000">pointed
  out</a>, the philosophy of AI is ''unlikely to have any more effect
  on the practice of AI research than philosophy of science generally
  has on the practice of science.''
</p>

<% partial 'partials/exercise', locals: { name: 'What is AI, really? (1p)' } do %>

<p>
  Your first exercise will be to take a look into current AI research.
  Find an AI-related scientific article from recent years. Pick one
  that you can understand, by and large: try to see what the problem
  statement, methodology, and conclusions are, roughly.
</p>

<p>
  Good places to start your search are, e.g., the proceedings of
  <a href="http://www.aaai.org">AAAI</a>,
  <a href="http://www.ijcai.org">IJCAI</a>, and
  <a href="https://www.eurai.org/activities/ECAI_conferences">ECAI</a>
  conferences or magazine-style publications that may be somewhat less
  technical and intended for broader audiences, such
  as <a href="http://ai-magazine.com/">AI Magazine</a>. However,
  please try to avoid articles that are overly polemic and
  superficial -- the idea is to take a look at <i>academic</i> AI,
  and ignore the BS on my Facebook feed...
</p>

<p>
  Read the article through and answer the following questions:
  <ol>
    <li> What is the research problem?
    <li> Is the topic related to the topics of this course?
    <li> Generally speaking, what impression does the article give
      about modern AI research? Reflect on the history and philosophy of
      AI discussed above.
    <li> What studies would be needed to undertand the article in detail?
    <li> Bonus question: Considering the article you chose, how relevant
      is the ''Terminator'' scenario where AI becomes self-conscious and
      turns against the humankind?
  </ol>
</p>

<% end %>

<!-- Exercise 1.1 -->

<% partial 'partials/solution', locals: { name: 'Example solution' } do %>

  <p>
    Most of the articles tend to be quite technical and focused
    on a narrow sub-problem.
  </p>
  
  <p>
    The technical background required often includes maths such as
    formal logic and probability calculus, and computer science
    topics such as algorithms and data structures.
  </p>
  
  <p>
    To take a concrete example, we can take a look at the article
    <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewFile/15001/14466">Polynomial Optimization Methods for Matrix Factorization</a>
    by P.-W. Wang, C.-L. Li, and J.Z. Kolter, which appeared in the
    AAAI-17 conference.
  </p>
  
  <p>
    <ol>
      <li>
        The article presents new algorithms for factorizing matrices
        (representing big matrices as products of smaller matrices)
        that are based on certain optimization techniques. Matrix
        factorization can be used in various machine learning scenarios.
        For example, many state-of-the-art recommender systems that
        predict user ratings of items such as movies or music include
        matrix factorization as a key component. Improving matrix
        factorization algorithms will thus eventually lead to better
        movie and music recommendations.
      <li>
        The article is clearly relevant to the course topics
        (machine learning and recommendation systems in particular).
      <li>
        Based on this article alone, AI research would appear to
        differ only slightly from mathematics research. The emphasis
        on practical solutions and empirical evaluation is a feature
        characteristic to AI and ML research.
      <li>
        The paper uses advanced multivariate calculus tools. From an
        algorithmic point of view, there is actually nothing intricate
        (basically a few loops), and the maths background is the area
        where further studies would be required to get the details.
      <li>
        The article doesn't mention consciousness or any other
        "philosophical" issues at all. The problem is clearly
        constrained as that of minimizing a function. The progress
        in AI that this paper makes is quantitative, not
        qualitative.
    </ol>
  </p>
  
  <% end %>

<% partial 'partials/hint', locals: { name: 'How do I return my solutions?' } do %>

<p>
  Solving the above exercise gives you one point (1p). Some exercises such
  as Ex1.4 below require a bit more effort, and they may give you
  two point (2p). This is indicated in the exercise heading as above.
</p>

<p>
  Solutions to ''pencil-and-paper'' exercises such as this one
  are returned at the exercise sessions where you should make sure
  to mark completed exercises on the sheet that is circulated in
  the beginning.
</p>

<p>
  For programming exercises, you will be able to use the TMC system
  which helps you see whether the solution is correct. However,
  even the TMC exercises are marked at the exercise session.
  In other words, <b>it is not enough to upload the programming
    exercises on TMC to get the points</b>.
</p>

<% end %>



<p>
  We will now put our wine glasses aside, roll our sleeves, and turn
  our minds toward more practical considerations.
  Let's jump to our first technical topic:
  search and problem-solving.
</p>

<% partial 'partials/material_heading' do %>
  Search and Problem-Solving
<% end %>

<p>
  Many problems can be phrased as search problems. Formulating the
  search space and choosing an appropriate search algorithm often
  requires careful thinking and is an important skill for an AI
  developer.
</p>

<p>
  Basic tree and network traversal algorithms belong to the
  course prerequisites, and you should already be familiar with
  breadth-first, depth-first, and best-first search (including its
  special case, the A* algorithm). If you forgot the details right
  after taking the exam, no need to worry: we will revisit them
  below.
</p>

<% partial 'partials/material_sub_heading' do %>
  Formulating Problems as Search
<% end %>

<p>
  Being able to solve AI problems by search requires that we first
  formula the problem in a certain way.
</p>

<% partial 'partials/hint', locals: { name: 'Search Space, Transitions, Costs' } do %>

<p>
  The key concepts are the set of allowed <b>states</b>, called the </b>search space</b>,
  and <b>transitions</b> between them. Sometimes different transitions have 
  different <b>costs</b> associated with them: think, for example, a tram
  or air travel network where the distances between two stops or
  airports are different. The cost can be sometimes measured in kilometers,
  sometimes in hours and minutes, and sometimes in some other resources.
</p>

<p>
  The <b>state transition diagram</b> is a diagram where each allowed
  state is a node and the allowed transitions between them are shown
  as edges connecting the nodes.
</p>

<% end %>

<p>
  In the lecture, we discussed an example involving three missionaries
  and three cannibals. They were all trying to cross a river with a boat
  that can only carry two people at a time. Crossing the river two at a
  time would otherwise be quite simple, but there's an additional 
  constraint that there can never be more missionaries than cannibals
  on either side of the river, unless the number os cannibals is zero.
  (This is because the missionaries, if they can overpower the cannibals,
  will convert them &mdash; and we don't approve of such colonial intrusion
  into people's religious beliefs.)
</p>

<p>
  We can represent each state by listing the missionaries and cannibals
  as well as the boat on each side of the river so that
  <pre>
           mmcc|mcb
</pre>
  means that there are two missionaries (mm) and two cannibals (cc)
  on the left bank of the river, and one missionary and one cannibal
  and the boat (mcb) on the right bank. The initial state and the
  goal state are 
<pre>
     initial:      mmmcccb|
     goal:         |mmmcccb
</pre>
</p>

<p>
   The state transition diagram would then contain, for example, the
   following states and edges
<pre>
            mmmcccb| --- mmcc|mcb --- mmcccb|m
               \                         \
                \                         \
              mmccc|mb                  ccc|mmmb
</pre>
where the two possible transitions from the initial state at the
top-left corner involve either one missionary and one cannibal or
one missionary alone crossing the river. The latter transition
leads to a dead-end situation where one missionary is on the
right bank alone with the boat and the only option is that she
goes back only to end up in the initial state.
</p>

<p>
   The point in all this is that while possibly rather dull and tedius, 
   constructing the state transition diagram is a routine operation. 
   Since the search procedure is also fully
   automatic, we can solve the problem without having to use our own
   wits. Still, this technique can be used to solve puzzles and problems
   that most of us would think of requiring ''intelligence''.
   Small puzzle tasks like the Missionaries and Cannibals 
   puzzle are probably easier to solve manually than by writing a
   computer program to solve them. However, the real power of the AI approach
   becomes clear in large-scale problems where our human intelligence
   can't handle all the possible options.
</p>

<% partial 'partials/material_sub_heading' do %>
  Breadth-First and Depth-First Search
<% end %>

<p>
  To set the scene for discussing more advanced search algorithms,
  such as A*, we begin by defining a generic templace for search
  algorithms.
</p>

<% partial 'partials/code_highlight' do %>
1:  search(start_node):
2:     node_list = list()                # empty list (queue/stack/...)
3:     visited = set()                   # empty set
4:     add start_node to node_list
5:     while list is not empty:
6:        node = node_list.first()       # pick the next node to visit
7:        remove node from node_list
8:        if node not in visited:
9:           visited.add(node)
10:          if goal_node(node):
11:             return node              # goal found
12:          add node.neighbors() to node_list
13:       end if
14:    end while
15:    return None                       # no goal found
<% end %>

<p>
  In the above pseudo-code, <code>node_list</code> holds the nodes to
  be visited. The order in which nodes are taken from the list
  by <code>node_list.first()</code> determines the behavior of the
  search: a queue (first-in, first-out) results in <b>breadth-first
  search (BFS)</b> and a stack (last-in, first-out) results
  in <b>depth-first search (DFS)</b>.
</p>

<p>
  In case of BFS, the operation of adding a node to the list (queue)
  is <i>enqueue</i> and the operation of removing the node that was
  added first is <i>dequeue</i>.
</p>

<p>
  In the case of DFS, the operation of adding a node to the list (stack)
  is <i>push</i>, and the operation of removing the node that was
  added last is <i>pop</i>.
</p>

<p>
  The test <code>goal_node</code> tests whether the goal or target node
  of the search is found. Sometimes the problem is simply to traverse the
  network (or tree) completely in a particular order, and there is no
  goal node. In that case, <code>goal_node</code> simply always returns
  <code>False</code>.
</p>

<% partial 'partials/hint', locals: { name: 'But this isn&rsquo;t how Granma taught it to me!' } do %>
<p>
  You may have seen different versions of search algorithms and wonder why
  this isn't exactly like them. In particular, many students have been
  taught the recursive version of DFS, which indeed is very simple
  and elegant.
</p>

<p>
  You need not worry about the difference too much. Here we simply wanted
  to use the same template for all search methods. The behavior is
  always the same: for example, the recursive version of DFS actually
  uses a stack to store the state of the search and pops the next
  state from the stack just like our non-recursive version above.
</p>
<% end %>

<p>
  It is quite straighforward to see that BFS will always return the
  path with the fewest transitions to a goal node: if node A is nearer
  to the starting node than node B, the search is expanded to node A
  earlier than to B. You can think of the BFS search as
  a <i>frontier</i> of nodes that gradually progresses outwards from
  the starting node, so that all nodes at a certain number of
  steps away are expanded before moving one step ahead.
</p>

<p>
  DFS doesn't guarantee that the shortest path be found, but in some
  cases it doesn't matter. See the lecture slides for an example of
  solving Sudoku puzzles using DFS. Can you think of a reason by
  DFS is a better choice in that problem that BFS?
</p>

<p>
  Here's a simple exercise to make sure BFS and DFS are clear enough.
</p>

<% partial 'partials/exercise', locals: { name: 'Breadth-first and depth-first search (1p)' } do %>

<p>
  <img width=30% src="/img/exercises/ex1/Drawing.png" align=right>
  Consider the (cute) network on the right.
</p>

<p>
  <ol>
    <li> Simulate (on pencil-and-paper) breadth-first search starting from
      node A when the goal node is H.
    <li> Do the same with depth-first search.
  </ol>
  In each case, present the contents of the node list (queue or stack)
  at each step of the search. To ensure that everyone gets the same
  result, let's agree that nodes are added to the list in alphabetical
  order.
</p>

<% end %>

<!-- Exercise 1.2 -->

<% partial 'partials/solution', locals: { name: 'Example solution' } do %>

<p>
  Here's the traversal order in the format <code>node: [node list]</code>:
<pre>
      BFS            DFS
      a: [b]         a: [b]
      b: [c,f]       b: [f,c]
      c: [f,e,i]     f: [g,d,c]
      f: [e,i,d,g]   g: [h,d,c]
      e: [i,d,g]     h = goal
      i: [d,g]
      d: [g]
      g: [h]
      h = goal
</pre>
</p>

<% end %>

<p>
  As we discussed above while drinking red wine, search algorithms don't
  necessarily feel like being very cool AI methods. However, as the
  next two exercises demonstrate, they can actually be used to solve
  tasks that -- most of us would admit -- require intelligence.
</p>

<% partial 'partials/exercise', locals: { name: 'Towers of Hanoi (1p)' } do %>

<p>
  Let's play. Solve the well-known
  puzzle <a href="https://www.britannica.com/topic/Tower-of-Hanoi">Towers
    of Hanoi</a>. The puzzle involves three pegs, and three discs: one
  large, one medium-sized, and one small.  (Actually, there can be any
  number of discs but for the pencil-and-paper exercise, three is plenty.)
</p>

<p>In the initial state, all three discs are stacked in the first
  (leftmost) peg. The goal is to move the discs to the third peg.
  You can only move one disc at a time, and it is not allowed to
  put a larger disc on top of a smaller disc.</p>

<p>This pretty picture shows the initial state and the goal state:
<pre>
initial  -     |     |          goal    |     |     -
state:  ---    |     |          state:  |     |    ---
       -----   |     |                  |     |   -----
      =====================         ====================
</pre>
</p>

<p>
  <ol>
    <li> Draw a network diagram where the nodes are all the states
      that can be achieved from the initial state, and the edges
      represent allowed transitions (moves) between them.
    <li> Simulate breadth-first search in the state space.
      <b>Note:</b>You don't have to explicitly specify the
      contents of the queue at each step. It is enough to provide
      the traversal order.
    <li> Do the same with depth-first search.
    <li> Compare the search methods on two accounts: <i>a)</i>
      what is the length of the path that each algorithm finds,
      <i>b)</i> what is the number of states visited during the
      search. <b>Note:</b> It is important to note that these are
      two different things (the length of the path, and the number
      of visited states.)
    <li> Does the result depend on the order in which the neighbors
      of each node are added into the list?
  </ol>
</p>

<p>A bonus exercise: Try to see the symmetry in the state diagram,
  and generalize to <i>n > 3</i> discs.
</p>

<% end %>

<!-- Exercise 1.3 -->

<% partial 'partials/solution', locals: { name: 'Example solution' } do %>

<p>
  <ol>
    <li>
      Here's the state diagram (from <a href="https://en.wikipedia.org/wiki/Tower_of_Hanoi">Wikipedia: Towers of Hanoi</a>):<br><br>
      <img src="/img/diagrams/880px-Tower_of_Hanoi-3.svg.png" width=62%><br><br>
      The encoding is such that the first letter in a three-letter
      sequenceencodes the position of the smallest disk
      (<code>a</code> = left, <code>b</code> = middle,
      <code>c</code> = right), the second letter encodes the
      position of the middle disk, and the third letter encodes the
      position of the largest disk. Thus, there is a transition from the
      starting state <code>aaa</code> to states <code>baa</code> and
      <code>caa</code>, where the smallest disk is move to the middle
      or the right-most peg respectively.
    <li>
      BFS visits the states in the following order:
      <code>aaa [start], baa, caa, bca, cba, aca, cca, aba, bba,
	ccb, bbc, acb, bcb, abc, cbc, abb, bab, acc, cac,
	bbb, cbb, aab, cab, bcc, ccc [goal]</code>.
      Minor differences are possible due to different ordering of
      the neighbors of each node.
    <li>
      DFS visits the states in the following order:
      <code>aaa [start], caa, cba, bba, bbc, cbc, cac, bac, bcc, ccc
	[goal]</code>.
      Here the order in which the neighbors are considered can have a
      significant effect on the result. In the worst case, all other
      nodes are visited before expanding the goal node.
    <li>
      <i>a)</i> The path produced by BFS is the one with the least
      possible transitions, seven. The path produced by DFS, on the
      other hand, is the same as the sequence of states visited by
      DFS, which is ten transitions in length.
      <i>b)</i> BFS visited 25 states altogether while DFS only visited
      11 states. So BFS visits much more states but produces a shorter
      path.
    <li>
      The number of states visited by BFS varies only slightly, and
      the path that it produces is always the same (since the shortest
      path is unique). However, DFS can either go straight to the
      goal by visiting only the states that are on the shortest path,
      or it can visit almost all states in the state space, and
      produce the maximally long path from the start to the goal.
  </ol>
</p>

<p>
  On the bonus exercise, see the Wikipedia page mentioned above.
</p>

<% end %>

<% partial 'partials/exercise', locals: { name: 'Travel Planner (2p)' } do %>

<p>
  Now it's time for this week's highlight: implementing a real AI
  application. It will require some effort, and programming can often
  be slow and frustrating, but stay focused, don't hesitate to ask for
  help, and you'll be ok. Next week, we'll continue working on the
  same application, so your hard work now will make your life easier
  next week.
</p>

<p>
  The task is to read Helsinki tram network -- outdated, we're afraid
  so it's not going to be super useful -- data from a file that we give.
  Implement a program that takes as input the starting point A and
  the destination B, and finds the route from A to B with the
  <i>fewest stops</i> between them. It is quite straightforward to
  show that such a route can be found by BFS.
</p>

<p>
  We provide a Java template that includes a <code>Stop</code> class
  which can retrieve the neighboring stops. These are the valid
  transitions in the state space.
</p>

<p>
  You can also start from scratch and implement your solution in
  your favorite programming language. In that case, simply take the
  <code>network.json</code> file, which is pretty self-explanatory.
  A hint to Python programmers: <code>import json</code>.
</p>

<p>
  If using the Java template (others may find these instructions
  useful too):
  <ol>
    <li>
      Download and open the Maven project in a suitable development
      environment (e.g., Netbeans).
    <li>
      Implement the search algorithm in
      class <code>TravelPlanner</code>.
    <li>
      In order to be able to
      extract the resulting route after the search ends, construct a
      backward-linked list of <code>Stop</code> objects as the stops
      are added into the queue, each of which has a pointer to the
      previous stop from which the search arrived at the stop in
      question. This way, once you arrive at the destination, you can
      start backtracking along the shortest path until the beginning.
    <li>
      Test your solution on TMC to see that your TravelPlanner works
      as it should and doesn't send you on a detour.
  </ol>
</p>

<p>
  If you don't use TMC, you can test by setting the starting stop as
  <code>1250429(Metsolantie)</code> and the destination as
  <code>1121480(Urheilutalo)</code>. The path (listed backwards) with
  the fewest stops is as follows:
<pre>
1121480(Urheilutalo)[DESTINATION] -> 1121438(Brahenkatu) -> 1220414(Roineentie)
-> 1220416(Hattulantie) -> 1220418(Rautalammintie) -> 1220420(Mäkelänrinne)
-> 1220426(Uintikeskus) -> 1173416(Pyöräilystadion) -> 1173423(Koskelantie)
-> 1250425(Kimmontie) -> 1250427(Käpylänaukio) ->1250429(Metsolantie)[START]
</pre>
</p>

<% end %>

<!-- Exercise 1.4 -->

<% partial 'partials/solution', locals: { name: 'Example solution' } do %>

  <p>
    You can download working solutions here: <a href="https://materiaalit.github.io/intro-to-ai/files/TravelPlanner.java">Java</a>, <a href="https://materiaalit.github.io/intro-to-ai/files/TravelPlanner_model_python.zip">Python</a>.
  </p>

<% end %>

<p>
  Alright. So far, we've refreshed BFS and DFS in our memory and
  applied them to solve some pretty cool applications. To go to the
  next level, we'll bring out the big guns, and talk about best-first
  search (which is <b>not</b> abbreviated in order to avoid confusing
  it with breadth-first search) and the A* algorithm.
</p>

<p>

</p>

<% partial 'partials/material_sub_heading' do %>
  Informed Search and A*
<% end %>

<p>
  Often, different transitions in the state space are associated with
  different costs.  For example, doing a task could take
  any time between a few seconds and several hours. Or the distance
  between any two tram stops could be between a hundred meters and half
  a kilometer.  Thus, just counting the <i>number</i> of transitions
  is not enough.
</p>

<p>
  To be able to take into account different costs, we can apply
  <b>best-first search</b>, where the node list is ordered by a given
  criterion. For instance, we can choose to always prefer to expand a
  path with the minimal incurred total cost counting from the starting
  node. This is known as <b>Dijkstra's algorithm</b>. In the special
  case where the cost of all transitions is constant, Dijkstra's
  algorithm is equivalent to BFS.
</p>

<p>
  The generic search algorithm template above still applies, but in
  best-first search, the data structure that holds the nodes on the
  node list is a <b>priority queue</b>. When adding nodes to the
  priority queue on line 14, they are given a cost or a value that is
  then used to order the nodes in the queue.  (Depending on the
  application and whether the aim is to minimize or maximize the
  value, the queue can be a min-priority queue or a max-priority
  queue.)
</p>

<% partial 'partials/hint', locals: { name: 'Alice, Where Art Thou Going?' } do %>

<p>
  If you play around with
  the <a href="http://qiao.github.io/PathFinding.js/visual/">PathFinding
    applet</a> for a while, using BFS or Dijkstra's algorithm, you
  will quickly notice a problem. The search spreads out to all
  directions symmetrically without any preference towards the
  goal.
</p>

<p>
  This is understandable since the choice of the next node to expand
  has nothing to do with the goal. However, if we have some
  way of measuring, even approximately, which nodes are nearer
  to the goal, we can use it to guide the search and
  save a lot of effort by never having to explore unpromising
  paths. This is the idea behind <b>informed search</b>.
</p>

<% end %>

<p>
  Informed search relies on having access to a
  <b>heuristic</b> that associates with each node an estimate of the
  remaining cost from the node to the goal. This can be, for example,
  the distance between the node and the goal measured as the crow
  flies (i.e., Euclidean or geodesic distance -- or in plain words, a
  straight-line distance).
</p>

<p>
  Using the heuristic as the criterion for ordering the nodes in
  the (min-)priority queue will always expand nodes that appear to
  be nearer to the goal according to the heuristic. However, this
  may lead the search astray because the incurred cost of the path
  is not taken into account. A balanced search that takes both the
  incurred cost as well as the estimated remaining cost into account
  is obtained by ordering the (min-)priority queue by
  <pre>
           f(node, cost) = cost + h(node),
  </pre>
  where <code>cost</code> is the value associated with the node when
  it is added to the priority queue, and <code>h(node)</code> is the
  heuristic value, i.e., an estimate of the remaining cost
  from <code>node</code> to the goal. This is the <b>A* search</b>.
  If you try it on
  the <a href="http://qiao.github.io/PathFinding.js/visual/">PathFinding
  applet</a>, you will immediately see that it wipes the floor with
  other, uninformed search methods.
</p>


<p>
  This is the end of Part 1. You should complete this part during the
  first week of the course. (The exercise sessions where the problems
  are discussed are held the following week.) In the next part, we
  will study two topics: Games, and Reasoning under Uncertainty (which
  we'll continue for some time). 
</p>
