---
  title: Part 4
  exercise_page: true
  quiz_page: false
  published: true
---




<% partial 'partials/exercise', locals: { name: 'Bayesian networks (pencil-and-paper) (1p)' } do %>

<p>
  In Part 3, we briefly discussed how Bayesian networks lead to compact
  representation of probabilistic models.
  <ol>
    <li>
      Consider a model with N=4 variables, each of which has k possible
      values (0,1,...,k&ndash;1). How many different elementary events are there
      in the domain? One less is the number of probabilities that we'd have
      to determine in order to fully specify the model. (For example, in the
      Car model of Part 3, with N=6 and k=2, this number was 63.)
    <li>
      How many parameters would we have to define to specify the model using
      an "empty" Bayesian network, i.e, a network with no edges at all?
    <li>
      What is the maximum number of parameters we'd have to define in a
      Bayesian network in this domain (N variables with k values each)?
      Remember that the graph has to be a DAG, i.e., no directed cycles are
      allowed.
    <li>
      <i>Optional:</i> Generalize to arbitrary values of N. It may be helpful to
      recall the sum of a geometric series 1+k+k<sup>2</sup>+...+k<sup>N&ndash;1</sup> =
      (k<sup>N</sup>&ndash;1)/(k&ndash;1), where k&ne;1.
  </ol>
</p>

<% end %>

<!-- Excercise 4.1 -->

<% partial 'partials/solution', locals: { name: 'Example solution' } do %>

  <p>
    <ol>
      <li>
        The number of combinations is k<sup>N</sup> = k<sup>4</sup>.
        Since the probabilities of the elementary events must sum to
        one, it is enough to give k<sup>4</sup>&ndash;1 probability
        values to define the model this way.<br><br>
      <li>
        In an empty network, we only need to specify the distributions
        of each variable. Since each variable has k possible values, we
        need k&ndash;1 probabilities per variable, and the total number
        is N(k&ndash;1) = 4(k&ndash;1).<br><br>
      <li>
        The more edges there are in the network, the more parameters are
        required in order to specify all the conditional
        distributions. Thus, we need to calculate how many parameters
        there are in the "full" network. A full network has one node
        with no parents, one node with one parent, one node with two
        parents, etc.<br><br>
  
        For a node with m parents, the number of possible parent
        configurations is k<sup>m</sup> (since we assumed that the
        number of values that each parent can take is k). To specify
        the conditional distribution for all parent configurations,
        we thus need k<sup>m</sup>(k&ndash;1) probability parameters.<br><br>
  
        Summing up the numbers over the N=4 nodes, we thus get k&ndash;1
        + k(k&ndash;1) + k<sup>2</sup>(k&ndash;1) +
        k<sup>3</sup>(k&ndash;1).
        <br><br>
  
      <li>
        For general N, the above formula becomes<br><br>
        (1 + k + k<sup>2</sup> + ... + k<sup>N&ndash;1</sup>)(k&ndash;1)
        = k<sup>N</sup>&ndash;1,
        <br><br>
        where we used the formula for the sum of a geometric series.
    </ol>
  <% end %>



<% partial 'partials/exercise', locals: { name: 'Bayesian networks: Car (programming) (1p)' } do %>

<p>
  Implement an algorithm for generating data from the Car network
  discussed in Part 3.  You should generate n tuples, each of which is
  a six element list of bits (or Boolean values). You should start by
  choosing the value of B so that it takes value 1
  (or <code>True</code>) with probability 0.9. After choosing the
  value of B, choose the value of R. If B=0, then R=0 with probability
  1. If B=1, then R=0 with probability 0.1. Continue this way,
  choosing the probabilities from the CPTs, until you have generated a
  complete tuple.
</p>

<p>
  Generate a sample of n=100 000 tuples. Use it to approximate the following
  conditional probabilities:
  <ol>
    <li>
      P(B | R,G,&not;S)
    <li>
      P(S | R,I,G)
    <li>
      P(S | &not;R,I,G)
  </ol>
  <strong>
    and (don't forget this part):
  </strong>
  <ol start=4><br>
    <li>
      Give an interpretation to the above probabilities. Are they in line with
      your intuition? In other words, do they make sense?
  </ol>
</p>

<% end %>

<p>
  Consider the following scenario. You live in an area where
  earthquakes happen on the average every 111th day. Another annoying
  thing is that a burglar breaks into your home on the average once a
  year. Both events occur independently of each other and uniformly
  throughout the year (so any day is like another).
</p>

<p>
  In case of an earthquake, your home alarm goes off with probability 0.81.
  If your home is broken into, the alarm goes off with probability 0.92.
  If these both should occur at the same time, the alarm goes off with
  probability 0.97. If nothing special is going on, there's a false alarm
  with probability 0.0095.
</p>

<p>
  Now modify the algorithm from the previous exercise so that you can generate
  data from variables [E]arthquake, [B]urglar, [A]larm. Generate a sample of
  n=100 000 tuples.
  <ol>
    <li>
      Among the tuples with A=1, what is the fraction where B=1?
    <li>
      Among the tuples with A=1 and E=1, what is the fraction where B=1?
  </ol>
  <strong>
    and (don't forget these):
  </strong>
  <ol start=3><br>
    <li>
      Give an interpretation to your answers for items 1 & 2. What
      probabilities do they approximate?
    <li>
      Are they in line with your intuition? In other words, do they
      make sense? In particular: which of the fractions is bigger and
      why?
    <li>
      Repeat the experiment a couple of times to get a feeling of how much
      the results change just by chance. (This is the nature of the Monte
      Carlo approximation.) Experiment with different values of n. How does
      it affect the variability?
  </ol>
</p>
  

You can find the lecture slides for this part on the <a href="https://studies.helsinki.fi/courses/cur/hy-opt-cur-2021-3a70433a-d793-46a4-a43e-a42968419133">course homepage</a>
under Materials.


<% partial 'partials/material_heading' do %>
  Machine Learning
<% end %>

<p>
</p>

<% partial 'partials/hint', locals: { name: 'Learning objectives of Part 4' } do %>

<table class="table">
  <tr>
    <td>
      Theme
    </td>
    <td>
      Objectives (after the course, you ...)
    </td>
  </tr>
    <td>
      Machine learning
    </td>
    <td>
      <ul>
	<li>can distinguish between unsupervised and supervised machine learning scenarios
	<li>can implement at least two supervised classification methods (e.g., naive Bayes, nearest neighbour classifier)
	<li>know the main types of neural networks (feed-forward, recurrent, self-organizing map) and their main principles
	<li>can implement the perceptron algorithm in a simple binary classification problem
      </ul>
    </td>
  </tr>
</table>

<% end %>

<% partial 'partials/material_sub_heading' do %>
  Kinds of Machine Learning
<% end %>

<p>
  It has been long understood that <b>learning</b> is a key element of
  intelligence. This holds both for natural intelligence -- we all get
  smarter by learning -- and artificial intelligence. In the latter
  case, learning is called <b>machine learning</b>.
</p>

<p>
  The roots of machine learning are in statistics, which can also be
  thought of as the art of extracting knowledge from data. Especially
  methods such as linear regression and Bayesian statistics, which are
  both already more than two centuries old (!), are even today at the
  heart of machine learning. For a brief history, see
  the <a href="https://en.wikipedia.org/wiki/Timeline_of_machine_learning">timeline
  of machine learning</a> (Wikipedia).
</p>

<p>
  The area of machine learning is often divided in subareas according
  to the kinds of problems being attacked. A rough categorisation is
  as follows:
  <ol>
    <li>Supervised learning
    <li>Unsupervised learning
    <li>Reinforcement learning
    <li>...
  </ol>
  The categories are somewhat overlapping or fuzzy (pardon my French),
  so a particular method can sometimes be hard to label. For example,
  as the name suggests, so called <i>semisupervised</i> learning is
  partly supervised and partly unsupervised.
</p>

<p>
  We will focus primarily on supervised learning, and in particular,
  <b>classification tasks</b>. In classification, we observe in input,
  x, and try to infer its "class" y. There can be two or more possible
  class values. In the standard case, it is assumed that in each case,
  exactly one class value is "correct". In other words, it is not
  possible that an instance belongs to multiple classes (or none at
  all) at the same time. The <b>training data</b> is in the form of a
  set of (x,y) pairs.
</p>

<p><b>Classification error</b> means the fraction of incorrect
  classifications, i.e., cases where our classifier outputs the wrong
  class. It is important to keep in mind that the classification error
  can be quite different in the training data and a separate <b>test
    set</b>. This is related to the so called <a href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a> phenomenon. More about this very
  important topic on other courses such as <i>Introduction to Machine
    Learning</i>.
</p>

<p>
  Good examples of classification tasks include: spam filtering (input
  is set of words in the message, class is spam/ham) and handwritten
  digit recognition (input is a bitmap image, class is 0,...,9).
</p>
<img src="/img/diagrams/MNISTsamples.png" width=88%>

<p>
  <i>Figure:</i>&nbsp; Samples of handwritten images from the very
  commonly used <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>
  dataset. The correct label (decided by a human) is shown above each
  image. Note that some of the "correct" class labels are questionable:
  see for example the second image from left: is that really a '7',
  or actually a '4'?
</p>

<p>
  In this part, we'll study three classic and commonly used
  classifiers: first, the nearest neighbor classifier, second, the
  naive Bayes classifier (which is already familiar to you from the
  spam filter in Part 3), and third, the perceptron neural network
  classifier.
</p>

<% partial 'partials/material_sub_heading' do %>
  k-Nearest Neighbor (k-NN) Classifier
<% end %>

<p>
  The <b>nearest neighbor</b> (NN) classifier is among the simplest
  possible classifiers. In the training stage, if you can call it
  that, all the training data is simply stored. When given a new
  instance, x<sup>(test)</sup>, we find the training data point
  x<sup>(NN)</sup> which is closest to x<sup>(test)</sup> and
  output its class label y<sup>(NN)</sup> as the predicted class
  label. An example is given in the following diagram (panels a and b).
</p>

<img src="/img/diagrams/nearestneighbors_diagram1.png" width=90%><br><br>

<p>
  In the k-nearest neighbor (k-NN) classifier, the idea is very
  similar but here it is not only the single nearest point that is
  used. Instead, we find the k nearest training data points, and
  choose the majority class among them as the predicted label.
  This is illustrated in panel c of the above diagram.
</p>

<% partial 'partials/hint', locals: { name: 'Faraway, So Close!' } do %>

<p>
  An interesting question related to (among other things) the NN
  classifier is the definition of <i>distance</i> or <i>similarity</i>
  between instances. In the illustration above, we implicitly assumed
  that the Euclidean distance is used. However, this may not always be
  reasonable or even possible: the type of the input x may be, e.g.,
  a string of characters (of possibly different lengths).</p>

<p>
  You should therefore choose the distance metric on a case-by-case
  basis. In the MNIST digit recognition case, we discussed the
  potential problems due to defining image similarity by counting
  pixel-by-pixel matches -- this was concluded to be sensitive to
  shifting or scaling the images. Fortunately, the MNIST data has
  been preprocessed by centering and scaling the images to alleviate
  some of these issues.
</p>

<% end %>

<% partial 'partials/material_sub_heading' do %>
  Naive Bayes Classifier
<% end %>

<p>
  The naive Bayes classifier is actually already familiar to you from
  the spam filter problem in Part 3. Here we will see how the same
  idea can be applied to handwritten digit recognition. In the
  spam filter application, the class variable was binary (spam/ham) and
  the feature variables were the words in the message. In the
  digit recognition application, the class variable has ten
  different values (0,...,9), and the feature variables are the
  28 &times 28 = 784 pixel values (binary black/white) in the bitmap
  images. We store the pixel values in a single vector and use the
  value X<sub>j</sub>=1 to indicate that the j'th pixel is white.
  The value X<sub>j</sub>=&ndash;1 is used for the black color
  for convenience.
</p>

<p>
  Here too, the feature variables are assumed to be independent of
  each other given the class value, i = 0,...,9. In the training
  stage, the algorithm estimates the conditional probabilities of each
  pixel being white in an image of class i for each class and each
  pixel. In the same manner as in the spam filter case, these
  probabilities can be estimated as empirical frequencies:<br><br>
  P(X<sub>j</sub> = 1 | Class = i) = #{X<sub>j</sub>=1, Class=i} /
  #{Class=i},
  <br><br>
  where #{X<sub>j</sub> = 1, Class=i} is the number of training instances
  of class i where the j'th pixel is white, and #{Class=i} is the
  overall number of class i instances.
</p>

<p>
  This estimator is implemented by the following pseudocode:
</p>

<% partial 'partials/code_highlight' do %>
train_NB(data):
1:  for each class i in 0,...,9:
2:     model.prior[i] = #{class=i} / n
3:     for each pixel j in 0,...,783:
4:        model.cpt[i,j] = #{X<sub>j</sub>=1, class=i} / #{class=i}
5:  return model
<% end %>

<p>
  The estimated values are stored as the array <code>cpt</code> in
  a <code>model</code> object. The array <code>prior</code> stores
  the estimates of the probabilities P(Class=i) for all i=0,...,9.
</p>

<p> Given a new image with pixel values
  x<sub>0</sub>,...,x<sub>783</sub> (so, for example, &ndash;1,&ndash;1,&ndash;1,1,... if the first
  three pixels are black and the fourth is white, etc) the classifier computes
  the joint probability<br><br>
  P(Class=i, X<sub>0</sub>=x<sub>0</sub>,...,X<sub>783</sub>=x<sub>783</sub>)
  = P(Class=i) P(X<sub>0</sub>=x<sub>0</sub> | Class=i) &times; ...
  &times; P(X<sub>783</sub>=x<sub>783</sub> | Class=i)
  <br><br>
  for all i=0,...,9.
  The sum of these probabilities over the ten class values,
  Z, is the annoying denominator in the Bayes rule, so we can obtain
  the posterior probabilities by dividing the above joint
  probabilities by Z:<br><br>
  P(Class=i | X<sub>0</sub>=x<sub>0</sub>,...,X<sub>783</sub>=x<sub>783</sub>)
  = P(Class=i) P(X<sub>0</sub>=x<sub>0</sub> | Class=i) &times; ...
  &times; P(X<sub>783</sub>=x<sub>783</sub> | Class=i) / Z
</p>

<p>
  Pseudocode for doing computing the posterior probabilities is
  below.
</p>


<% partial 'partials/code_highlight' do %>
posterior_NB(model, image):
1:  Z = 0; posterior = empty array
2:  for each class i in 0,...,9:
3:     posterior[i] = model.p[i]
4:     for each feature j in 0,...,783:
5:        if image[j] = 1:
6:           posterior[i] = posterior[i] * model.cpt[i,j]
7:        else:
8:           posterior[i] = posterior[i] * (1-model.cpt[i,j])
9:     Z = Z + posterior[i]
10: for each class i in 0,...,9:
11:    posterior[i] = posterior[i] / Z
12: return posterior
<% end %>

<p>
  Note that since the pixels can only take one of two possible values
  (white or black), the probability of a pixel being black is obtained
  as one minus the probability of a white pixel (line 8 in the
  pseudocode).
</p>

<p>
  To obtain a classifier that outputs a single class value, instead of
  the full posterior probability, we can pick the <b>maximum a
  posteriori</b> class value, i.e., the most probable class.
</p>

<% partial 'partials/material_heading' do %>
  Neural Networks
<% end %>

<p>
  Our next topic tends to attract more interest than many of the
  other topics on this course. Perhaps it is the hope to understand
  out own mind, which emerges from neural processing in our brain,
  that makes <b>neural networks</b> so interesting.
</p>

<% partial 'partials/material_sub_heading' do %>
  What is so Special about Neural Networks?
<% end %>

<p>
  The case for neural networks as an approach to AI is based on a
  similar argument as that for logic-based approaches. In the latter
  case, it was (or is) thought that in order to achieve human-level
  intelligence, we need to simulate higher-level thought processes,
  and in particular, manipulation of symbols representing certain
  concrete or abstract concepts using logical rules. The argument for
  neural computation is that by simulating the
  lower-level, <b>subsymblic</b> data processing on the level of
  neurons and neural networks, intelligence will emerge.
</p>

<p>
  Neural computation can even be thought to be an alternative to
  the conventional model of computation based on Turing machines.
  The main distinguishing features of neural computation compared to
  conventional computing are:
  <ol>
    <li>
      <b>parallelism:</b> many neurons act simultaneously
    <li>
      <b>stochasticity:</b> the behavior of neurons cannot be predicted
      in a deterministic fashion -- the same input can lead to
      different outputs
    <li>
      <b>massive scale:</b> neural networks can involve hundreds of billions
      (10<sup>11</sup>) connections -- which is still 10000 times less
      than the estimated number of connections in the brain,
      10<sup>15</sup>
    <li>
      <b>adaptivity:</b> the connections have an inherent tendency to adapt
      over time
  </ol>
</p>

<p>
  Artificial neural networks (ANNs) mimic natural neural networks by
  copying the basic idea of a connected system including a large
  number of simple processor units (neurons), where processing is
  carried out by transmitting signals between the neurons. However,
  the internal mechanism of the neurons is usually ignored and the
  artificial neurons are often much simpler than their natural
  counterparts. Likewise, the eletro-chemical signalling mechanisms
  between natural neurons are mostly ignored in the design of
  ANNs.
</p>

<p>
    There are attempts to simulate natural neural networks.
    The <a href="https://www.braininitiative.nih.gov/">BRAIN
    Initiative</a> led by American neuroscience researchers is pushing
    forward technologies for imaging, modeling, and simulating the
    brain at a finer and larger scale than before. Some brain research
    projects are very ambitious in terms of
    objectives. The <a href="https://www.youtube.com/watch?v=JqMpGrM5ECo">Human
    Brain Project</a> promised about 5 years ago that “the mysteries
    of the mind can be solved - soon”. After years of work, the Human
    Brain Project was facing questions about when
    the <a href="https://www.scientificamerican.com/article/why-the-human-brain-project-went-wrong-and-how-to-fix-it/">billion
    euros invested by the European Union and a consortium of industry
    partners</a> will deliver what was promised, even though, to be
    fair, some less ambitious milestones have been achieved.
</p>

<p>
  Most of the time, however, the goal is not to simulate a natural
  neural network but to implement AI and machine learning solutions.
  To build working solutions, it is not essential to replicate the
  details.  In practice, we usually build ANNs that differ from
  natural neural networks in at least the following ways:
  <ol>
    <li>
      computation in ANNs usually <b>synchronous</b>: all neurons complete
      their computation cycle before the proceeding to the next
      iteration, whereas natural systems tend to be asynchronous
    <li>
      signaling in ANNs is usually continuous-valued as opposed to the
      binary (on/off or fire/don't fire) signals between natural neurons
    <li>
      natural neural networks exhibit complex feedback loops
      -- only specialized ANNs known as <b>recurrent networks</b> have
      this feature (see below)
    <li>
      ANNs are often much smaller in scale than natural nervous systems
  </ol>
</p>

<% partial 'partials/material_sub_heading' do %>
  Weights, Activation and Adaptation
<% end %>

<p>
  The basic artificial neuron model involves a set of adaptive
  parameters, called  <b>weights</b>. These weights are used as
  multipliers on the inputs of the neuron. We denote the
  weighted sum of the inputs as:<br><br>
  z = &Sigma;<sub>j=1,...,n</sub> w<sub>j</sub> x<sub>j</sub>,
  <br><br> where n is the number of inputs. The weights are
  real-valued, and the inputs can be either binary or real-values.</p>

<p>
  The output of the neuron is obtained by applying an <b>activation
    function</b> on the weighted sum z. Typical examples is the
  activation function include:
  <ol>
    <li>
      step function: f(z) = &ndash;1, if z &lt; 0, and 1 otherwise
    <li>
      sigmoid function: f(z) = 1/(1+e<sup>&ndash;z</sup>)
  </ol>
</p>

<p>
  The output of a neuron can then act as the input of other neurons,
  whose outputs can be the input to yet other neurons, etc. The output
  of the whole network is obtained as the output of a certain
  subset of the neurons, which are called the <b>output layer</b>,
  although not all neural architectures can be divided in such a way.
</p>

<p>
  <b>Learning</b> or adaptation in the network occurs when the weights
  are adjusted so as to make the network produce the correct
  ouputs. Optimizing the weights manually is out of the question and
  learning ANNs is a machine learning problem.  Even as a machine
  learning problem, the optimization problems in ANNs are among the
  hardest.
</p>

<p>
  In the following, we will study three different kinds of neural networks:
  <ol>
    <li>
      feedforward networks, where the information always flows in one
      diretion (from an input layer toward an output layer)
    <li>
      recurrent networks, which include feedback loops
    <li>
      the self-organizing map
  </ol>
</p>

<% partial 'partials/material_sub_heading' do %>
  Feedforward Networks
<% end %>

<p>
  The simplest kind of ANNs from the point of view of their
  theoretical analysis are feedforward networks. Often the network
  architecture is composed of <b>layers</b>. The input layer consists
  of neurons that get their inputs directly from the data. So for
  example, in an image recognition task, the input layer would use the
  pixel values of the input image as the inputs of the input
  layer. The network typically also has <b>hidden layers</b> that use
  the other neurons' outputs as their input, and whose output is used
  as the input to other layers of neurons. Finally, the output layer
  produces the output of the whole network. All the neurons on a given
  layer get inputs from neurons on only a single (lower) layer.
</p>

<p>
  We will return to multilayer networks in a little while, but first
  we'll study the simplest possible neural "network" which consists of
  a single neuron.
</p>

<% partial 'partials/material_sub_sub_heading' do %>
  Perceptron: The Mother of all ANNs
<% end %>

<p>
  A <b>perceptron</b> is a feedforward neural network that consists of
  a single basic neuron. It was among the very first formal models of
  neural computation and because of its fundamental role in the
  history of neural networks, it wouldn't be unfair to call it the
  "Mother of all Artificial Neural Networks". It can be used as a
  simple classifier in binary classification tasks. A classic neural
  network method is the Perceptron algorithm, introduced by Rosenblatt
  in 1957, which can be used to train a perceptron.
</p>

<p>
  The perceptron neuron is simply the above basic neuron model with
  the step function as the activation function.
</p>

<p>
  In the Perceptron algorithm, for which pseudocode is given below,
  each misclassification leads to an update in the parameter vector w.
  If the predicted output of the neuron is 1 when the correct class is
  y=&ndash;1, then the input vector x is subtracted from the weight
  vector.  Similarly, if the predicted output is &ndash;1 when the
  correct class is y=1, then the input vector x is added to the weight
  vector. (Recall
  that <a href="https://www.mathsisfun.com/algebra/vectors.html">vector
  subtraction and addition</a> simply means the element-wise
  subtraction or addition of the two vectors.)
</p>

<% partial 'partials/code_highlight' do %>
perceptron(data):
1:  w = [0, ...,0]               # array of size p
2:  while error(data, w) > 0:
3:     (x,y) = choose_random_item(data)
4:     z = w[0]x[0] + ... + w[p-1]x[p-1]
5:     if z ≥ 0 and y = -1:      # -1 classified as 1
6:        w = w − x              # subtract vector x
7:     if z < 0 and y = 1:       # 1 classified as -1
8:        w = w + x              # add vector x
9:  return(w)
<% end %>

<p>
  In practice, it is impractical to choose random training data
  points on line 3 of the algorithm because this may lead to choosing
  correctly labeled examples most of the time, which is a waste of
  time since they lead to no updates in the weights.  Instead, a
  better method is to iterate through the training data and as soon as
  a misclassified item is found, do the required update.
</p>

<p>
  It can be theoretically proven that if the data is <b>linearly
    separable</b>, then the algorithm is guaranteed to stop after a
  finite number of steps and produce a weigth vector that correctly
  classifies all the training instances.
</p>

<% partial 'partials/exercise', locals: { name: 'Perceptron (programming) (2p)' } do %>

<p>
  Use the Perceptron template on TMC. (You can also implement your solution
  in other languages than Java. You'll find the necessary data files in the
  TMC template.)
</p>

<p>
  The file <code>mnist-x.data</code> contains 6000 images from the popular
  <a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a>, each
  of which is given on a single line in the file. Each image consists
  of 28 &times; 28 pixels listed row-by-row, so each line in the file
  contains 784 values.  Each pixel is either black (&ndash;1) or white
  (1). The file
  <code>mnist-y.data</code> contains the correct class value (0-9) of each
  of the 6000 images.
</p>

<p>
  Use the first 5000 images as training data and the last 1000 as test data.
  <ol>
    <li>
      Run the Java template to make sure that the file <code>test100.bmp</code>
      is created. It should include the first 100 images sorted according to
      the correct class label. This verifies that reading the file was
      successful.
    <li>
      Modify the <code>train()</code> method in
      class <code>Perceptron</code> so that it learns to distinguish
      number 3 from number 5. (Notice that the
      variable <code>targetChar</code> can be set to be one of these
      classes while <code>oppositeChar</code> should be the
      other. This will set the class label as 1 and &ndash;1 as is
      required in the Perceptron algorithm. Images representing other
      numbers are ignored.) Try to get a classification error around
      5&ndash;15 %.
    <li>
      Try other pairs of number than 3 vs 5. Which numbers are easiest to
      classify and which are the hardest?
  </ol>
<% end %>

<!-- Excercise 4.4 -->

<% partial 'partials/solution', locals: { name: 'Example solution' } do %>

  <p>
    An example solution is <a href="https://materiaalit.github.io/intro-to-ai/files/Perceptron-solution.zip">here</a>.
  </p>
  
  <% end %>


<% partial 'partials/exercise', locals: { name: 'Nearest Neighbor (programming) (1p)' } do %>

<p>
  Now implement a nearest neighbor classifier for the MNIST data used in
  the Perceptron exercise.
</p>

<p>
<!--  Given a test example, x<sup>(test)</sup>, the classifier will find
  the nearest training data point, X<sup>(NN)</sup>, and return its
  class label Y<sup>(NN)</sup>. -->
  Recall that unlike the Perceptron, or
  most other classifiers, the nearest neighbor classifier doesn't
  really involve a training stage.  All the action happens in the
  classification (testing) stage. This style of methods are sometimes
  called "lazy learning": thou shalt not let it be your inspiration in real
  life!
</p>

<p>
  Test your classifier using the same train/test split (5000/1000) as before.
  You can use the same pairs of numbers (3 vs 5), or even try classifying all
  the classes at the same time because the NN classifier is not restricted
  to binary classification. (Note that in multiclass classification, the
  expected accuracy tends to be lower than in binary classification simply
  because the problem is harder.)
</p>

<% end %>

<!-- Excercise 4.5 -->

<% partial 'partials/solution', locals: { name: 'Example solution' } do %>

  <p>
    An example solution is <a href="https://materiaalit.github.io/intro-to-ai/files/NearestNeighbor.java">here</a>.
  </p>
  
  <% end %>


<% partial 'partials/material_sub_sub_heading' do %>
  Multilayer perceptrons
<% end %>

<p>
  The main problem with the Perceptron algorithm is the assumption
  that the data are linearly separable. In practice, this tends not to
  be the case, and various variants of the algorithm have been
  proposed to deal with this issue. Two main directions are:
  <ol>
    <li>
      Applying a non-linear transformation on the original input
      data may produce a representation where the data are
      linearly separable. The so called "kernel trick" leads to
      a class of methods known collectively as <a href="https://en.wikipedia.org/wiki/Kernel_method">kernel methods</a>, among which the
      support vector machine (SVM) is the best known.
    <li>
      The model can be extended by coupling a number of basic
      neurons together to obtain neural networks that can represent
      complex, non-linear decision boundaries. A classical example
      of this is the <b>multilayer perceptron</b> (MLP).
  </ol>
</p>

<p>
  An illustration showing that the second option leads to non-linear
  decision boundaries is given by the following video:
  <ul>
    <li> Vimeo: <a href="http://vimeo.com/7932084">Two Spirals Problem</a>
  </ul>
</p>

<p>
  Optimizing the weights of a multilayer perceptron is much harder than
  optimizing the weigths of a single perceptron neuron. The second
  coming of neural networks in the late 1980s was largely due to
  the difficulties faced by the then prevailing logic-based approach
  (so called expert systems) but also due to the invention of the
  <b>backpropagation algorithm</b> in the 1970s-1980s.
</p>

<% partial 'partials/hint', locals: { name: 'Meanwhile in Helsinki (1970)' } do %>

<p>
  The path(s) leading to the backpropagation algorithm are rather long
  and winding. An interesting part of the history is related to the CS
  department of the University of Helsinki. About three years after
  the founding of the department in
  1967, <a href="http://people.idsia.ch/~juergen/linnainmaa1970thesis.pdf">a
  Master's thesis</a> was written by a student called Seppo
  Linnainmaa. The topic of the thesis was "Cumulative rounding error
  of algorithms as a Taylor approximation of individual rounding
  errors" (the thesis was written in Finnish, so this is a translation
  of the actual title "Algoritmin kumulatiivinen py&ouml;ristysvirhe
  yksitt&auml;isten py&ouml;ristysvirheiden
  Taylor-kehitelm&auml;n&auml;").
</p>

<p>
  The automatic differentiation method developed in the thesis was
  later applied by other researchers to quantify the sensitivity of
  the output of a multilayer neural network with respect to the
  individual weights, which is the key idea in backpropagation.
</p>

<% end %>

<p>
  After its discovery, the Perceptron algorithm received a lot of
  attention, not least because of optimistic statements made by
  its inventor, Frank Rosenblatt.  A classic example of AI hyperbole
  is a New York Times article published on July 8th, 1958:
  <blockquote style="margin-left: 40px; margin-right: 60px; background-color: #ecf0f1">
    <p>The Navy revealed the embryo of an electronic computer today
      that it expects will be able to walk, talk, see, reproduce itself
      and be conscious of its existence. Later perceptrons will be able
      to recognize people and call out their names and instantly
      translate speech in one language to speech and writing in
      another language, it was predicted.</p>
  </blockquote>
  The history of the debate that eventually lead to almost complete
  abandoning of the neural network approach in the 1960s for more than
  two decades is extremely fascinating. The
  article <a href="https://doi.org/10.1177%2F030631296026003005">"A
  Sociological Study of the Official History of the Perceptrons
  Controversy"</a> by Mikel Olazaran (Social Studies of Science, 1996)
  reviews the events from a sociology of science point of view.
  Reading it today is quite thought provoking -- and slightly
  chilling. Take for example a September 29th
  2017 <a href="https://www.technologyreview.com/s/608911/is-ai-riding-a-one-trick-pony/">article
  in the MIT Technology Review</a>, where Jordan Jacobs, co-founder of
  a multimillion dollar <a href="http://vectorinstitute.ai/">Vector
  institute for AI</a> compares Geoffrey Hinton (a figure-head of the
  current deep learning boom) to Einstein because of his contributions
  to the discovery of the power of the backpropagation algorithm in
  the 1980s and later.
</p>

<p>
  According to Hinton and Jacobs, we are on the brink of the final
  breakthrough. Sound familiar?
</p>

<p>
  Please note that neural network enthusiasts are not at all the only
  ones inclined towards optimism. The rise and fall of the logic-based
  "expert systems" approach to AI had all the same hallmark features
  of an AI-hype, including promising results in restricted domains,
  gullible journalists, clueless investors in their cabinets, and
  too much speed to notice how "minor obstacles" were piling up and
  becoming big problems. The outcome both in the early 1960s and late
  1980s was a collapse in the research funding, "AI Winter".
</p>

<% partial 'partials/material_sub_heading' do %>
  Recurrent Neural Networks
<% end %>

<p>
  As stated above, recurrent neural networks involve feedback loops
  so they cannot be organized in an input layer, a number of hidden
  layers, and an output layer.
</p>

<p>
  A classic example of this class of networks is the <b>Hopfield
    network</b>. In a Hopfield network, the neurons are binary
    (&ndash;1 or 1) and they are connected to each other by symmetric
    associative weights w<sub>i,j</sub>, which characterizes the
    strength of the association between neurons i and j. The
    association can be either positive or negative.
</p>

<p>
  In the learning stage, a number of joint states of all the neurons
  are used as training data, and the weights are fixed based on the
  number of times a pair of neurons are in the same state in the
  training data. The learning rule is given by<br><br>
  w<sub>i,j</sub> = &Sigma;<sub>k=1,...,n</sub> q<sub>ik</sub>
  q<sub>jk</sub> / n,<br><br>
  where q<sub>ik</sub>=1 if neuron i is in state 1 in training example
  k, and q<sub>ik</sub>=&ndash;1 otherwise.
</p>

<p>
  The neuron states can be given, for example, by pixels in a
  black-and-white image like in the MNIST task.
</p>

<p>
  After the learning stage, the network can be initialized by setting
  the neuron states in specific states. However, the neurons are not
  fixed to these states, but they are allowed to choose new states
  according to the current states of the other neurons and the
  associative weights w<sub>i,j</sub>. The specific learning rule
  is in fact the very same as the one used in the perceptron neuron,
  i.e., a linear combination of the other neurons states weighted
  by the weights passed through a step function.
</p>

<p>
  After all neurons have chosen their new state according to this
  rule, the same process is repeated so that the inputs of the neurons
  are given by the chosen new states.  The process tends to converge
  rapidly to a fixed point which can be taken as the output of the
  network.
</p>

<p>
  The Hopfield network can be used to implement an associative memory
  that retrieves typical patterns appearing in the training data given
  a partial match in the initial configuration. In practice, the
  Hopfield network is more significant as a conceptual model of how
  human or animal memory works than a technical tool for practical
  tasks.
</p>

<p>
  A practically more relevant ANN model is the <b>Boltzmann
  machine</b> which is essentially a stochastic version of the
  Hopfield network.  The main differences include the fact that the
  states of only a part of the neurons need to be given in the
  training data, and the learning and activation rules are
  different.
</p>

<p>
  An nice illustration of using the Boltzmann machine to reconstruct
  incomplete images is given in the following video:
  <ul>
    <li>
      Vimeo: <a href="http://vimeo.com/38359771">The Shape Boltzmann Machine</a>
  </ul>
</p>

<% partial 'partials/hint', locals: { name: 'What Should I Learn about Neural Networks?' } do %>

<p>
  The learning objectives related to neural networks are on a
  relatively high level: you should understand the basic idea (the
  learning method and the activation principles) in different kinds of
  ANNs. You should also learn what their main applications are. An
  exception is the perceptron classifier, which you should study in
  more detail -- that's why there is an exercise about it.
</p>

<% end %>


<% partial 'partials/material_sub_heading' do %>
  The Self-Organizing Map (SOM)
<% end %>

<p>
  A third category or ANNs is the <b>self-organizing map</b> (SOM). In
  fact, this "category" is really made of a single method, developed
  by the Finnish neural network pioneer Teuvo Kohonen in the early
  1980s.
</p>

<p>
  The neurons in a SOM are organized in a regular two-dimensional
  grid.  Each neuron has a weight or <b>state vector</b>. When an
  input, which is in the form of the same kind of vector as the state
  vectors, is presented, the neuron whose state vector is closest (in
  Euclidean distance) to the input vector is activated. This neuron is
  called the "winner".  The learning rule modifies the state of the
  winner so that it becomes even more similar to the input vector. An
  important feature of the learning procedure is that also the neurons
  that are next to the winner in the grid, which we call
  the <b>neighbors</b> of the winner, are modified in a similar
  fashion.
</p>

<p>
  A consequence of the learning procedure is that the state vectors of
  neurons that are located near each other in the grid tend to become
  more and more similar. Eventually, the result is a map where similar
  inputs activate nearby neurons. A typical application of the SOM is
  data visualization.
</p>

