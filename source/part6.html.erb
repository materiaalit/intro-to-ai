---
  title: Part 6
  exercise_page: true
  quiz_page: false
  published: true
---


<% partial 'partials/exercise', locals: { name: 'Robotics 1 (2p)' } do %>

<p>
  This week's exercises will be done partly on your own (just as
  usual) and partly at the workshops. You will get the points only
  by attending a workshop.
</p>

<p>
  Each student should register to one workshop (and attend it).
  Registration is done through a Doodle form (<a href="https://doodle.com/poll/9d7ypgtsikyvpaqh">Link</a>).
</p>

<p>
  In this task, you will get to play
  with <a href="https://shop.lego.com/en-US/LEGO-MINDSTORMS-NXT-2-0-8547">Lego
    Mindstorms NXT 2.0</a> robots. We will provide you with a pre-built robot,
  so unfortunately, no building is involved. The robot is a simple
  "car" with three wheels, a light sensor, and an ultrasonic sensor.
</p>

<p>
  Two of the wheels, the left and the right one, are connected to
  independent motors (<code>Motor.A</code> and <code>Motor.B</code>),
  and you can instruct them to rotate either forward or backward.
  To turn right, for example, you can rotate the left wheel forward and
  keep the right wheel still.
</p>

<p>
  The light sensor is in the front of the robot and points directly
  toward the floor. The ultrasonic sensor is attached to the left side
  of the robot, approximately 10cm behind the front of the robot, and
  it points directly to the left. See the drawing below to get
  a better idea (maybe).
</p>

<img src="/img/drawings/legorobo.png" width=75%><br><br>

<p>
  <i>Note:</i> You need not install the leJOS environment on your own
  computer. We will provide laptops with all the required tools to
  write Java code, compile, and connect to the robot. You will just
  have to code "blind" without being able to compile and test before
  the workshop. You'll have to finalize and debug your solution at the
  workshop.
</p>

<p>
  The lecture slides contain some basic instructions
  about leJOS programming. Here is some more material about the API:
  <ul>
    <li><a href="http://www.lejos.org/nxt/nxj/api/">leJOS API reference</a>
    <li><a href="https://lejos.sourceforge.io/nxt/nxj/tutorial/index.htm">leJOS NXJ Tutorial</a>
  </ul>
</p>

<p>
  <i>Task</i>: Make the robot follow a path marked by white tape
  on the floor. In the beginning, the robot will be placed on the path
  and it should move ahead, following the path. (You don't have to
  care what happens when the path ends.) You will be able to detect
  the path by using the readings from the light sensor.
</p>

<p>
  Use the following template to write a sketch of your solution. You
  should store your solution on a USB stick (or put it online) so that
  you can access it from the laptop at the workshop.
  <a href="https://materiaalit.github.io/intro-to-ai/files/HelloWorld.java">[download code]</a>
</p>

<% partial 'partials/code_highlight' do %>
package org.lejos.example;

import lejos.nxt.*;
import lejos.robotics.navigation.DifferentialPilot;

/**
 * Write your code in main()
 */
public class HelloWorld {

    static DifferentialPilot pilot = new DifferentialPilot(5.6, 17.5f, Motor.A, Motor.B);
    static UltrasonicSensor ultra = new UltrasonicSensor(SensorPort.S2);
    static LightSensor light = new LightSensor(SensorPort.S1);

    public static void main(String[] args) {
        System.out.println("I'll be back!");
        Button.waitForAnyPress();
    }
}
<% end %>

<p>
  <i>Hint:</i> Try to solve the task using as simple program logic as
  possible. In particular, it is not necessary that you maintain a
  detailed model of the environment (the path) and the position of the
  robot with respect to it. A useful strategy is to try to follow the
  right (or left) edge of the path, where the light readings change
  from high (path) to low (floor). You'll be able to estimate the
  actual values by printing out the readings on the robot screen
  at the workshop.
</p>

<% end %>

<% partial 'partials/exercise', locals: { name: 'Robotics 2 (2p)' } do %>

<p>
  Please use the registration link to the Robotics Workshops in
  Exercise 1 above.
</p>

<p>
  <i>Task:</i> "Park" the robot. The robot will be placed on a "street"
  that continues straight ahead, and where there are no obstacles.
  Drive ahead and use the ultrasonic sensor to detect whether there
  are obstacles to the left of the robot. Find an minimum
  40 &times; 40 cm parking spot, and drive the robot into it.
</p>

<p>
  <i>Hint:</i> The <code>DifferentialPilot</code> class will probably
  be useful. It can be instructed to drive ahead a given distance
  by <code>travel(distance)</code>. You can also set the robot moving
  by calling <code>travel(distance, true)</code>, in which case the
  command flow return to the next line of your code immediately,
  instead of waiting that the robot has first
  travelled <code>distance</code> cm. You can then query whether the
  robot is still moving by
  <code>isMoving()</code>.
</p>

<% end %>

<% partial 'partials/exercise', locals: { name: 'Feedback (2p)' } do %>

<p>
  The development of this course relies on your feedback. To give you
  a concrete incentive to give feedback, you'll even get exercise
  points for giving feedback!
</p>

<p>
  The deadline for this exercise is November 1 (one week after the
  course exam).
</p>

<p>
  Give feedback in both of the following ways:
  <ol>
    <li>
      First, submit anonymously through the university feedback
      system. You can find the feedback form in WebOodi.
    <li>
      <b>After you have submitted the anonymous feedback</b>, send
	email to the
	lecturer: <a href="mailto:teemu.roos@cs.helsinki.fi">
	teemu.roos@cs.helsinki.fi</a>.
  </ol>
</p>

<p>
  To get 1p for item 1, mention in your email that you have submitted
  the anonymous feedback through the feedback system &mdash; after actually
  doing so, of course.
</p>

<p>
  Also give feedback in the email. You can summarize your anonymous
  feeback briefly. Don't worry if the content is overlapping.
</p>

<% end %>

You can find the lecture slides for this part on the <a href="https://courses.helsinki.fi/en/data15001/129802916">course homepage</a>
under Materials.


<% partial 'partials/material_heading' do %>
  Robotics
<% end %>

<p>
  On this final part, we will encounter a <b>Grand Challenge</b>
  of AI, namely <b>Robotics</b>. Building and especially
  programming robots so that they can operate in complex,
  real-world scenarios requires a combination of virtually
  all areas of AI. For example:
  <ul>
    <li> computer vision and speech recognition  for
      sensing the environment
    <li> natural language processing, information retrieval, and
      reasoning under uncertainty for processing instructions and
      predicting consequences of potential actions
    <li> cognitive modeling and <a href="https://en.wikipedia.org/wiki/Affective_computing">affective computing</a> for interacting and
      working together with humans
  </ul>
</p>

<p>
  Many of the robotics-related AI problems are best approached by
  machine learning, so it is a very central branch of AI for robotics.
</p>

<p>
  Of course we cannot solve all the open problems in robotics.  Our
  objective is to first appreciate the challenges that operating under
  constraints on the sensor capabilities of robots, and second, to
  learn to implement simple functionalities despite such
  contraints. In practice, this will be done in fun robotics workshops
  where you'll be able to get your hands on actual robots.
  (Don't worry, no terminators involved.)
</p>


<% partial 'partials/hint', locals: { name: 'Learning objectives of Part 6' } do %>

<table class="table">
  <tr>
    <td>
      Theme
    </td>
    <td>
      Objectives (after the course, you ...)
    </td>
  </tr>
  <tr>
    <td>
      Digital Signal Processing and Robotics
    </td>
    <td>
      <ul>
	<li>appreciate the difficulty of implementing an autonomous robot in the real world
	<li>implement simple functionalities, e.g., following a line on the floor, using a robot with limited sensor capabilities
      </ul>
    </td>
  </tr>
</table>

<% end %>

<% partial 'partials/material_sub_heading' do %>
On the Mindstorms Robots
<% end %>

<p>
  We'll approach robotics in a very practical way, which is the only
  way to become familiar with the unique nature of robotics AI.
  The robots used on this course are Lego Mindstorms robots. They
  may be toys, but make no mistake, they can also teach us many
  things about operating in the real world with limited sensor
  capabilities.
</p>

<p>
  The system has a graphical programming environment but we'll use a
  more flexible Java-based <code>leJOS</code> environment that
  has a well-documented API for controlling the robot.
</p>

<% partial 'partials/material_sub_heading' do %>
  Movement: Controlling the wheels
<% end %>

<p>
  The kits that we'll provide you at the workshops (see Exercises 6.1
  and 6.2 above) have two motors, which you can control through the
  <code>NXTRegulatedMotor</code> class. The system automatically
  constructs two (actually three) instances of this
  class, <code>Motor.A</code> and <code>Motor.B</code>. They allow
  low-level control of the two wheels in the robot through
  methods such as <code>forward</code>, <code>backward</code>, and
  <code>stop</code>.
</p>

<p>
  Especially useful for Exercise 6.2 is also the
  higher-level <code>DifferentialPilot</code> class. The constructor
  takes as arguments the wheel diameter (in cm), the axis span
  (in cm), and the two motor objects. The following arguments work
  with our kits.
</p>
<% partial 'partials/code_highlight' do %>
static DifferentialPilot pilot = new DifferentialPilot(5.6, 17.5f, Motor.A, Motor.B);
<% end %>

<p>
  The <code>pilot</code> object can be used to drive the robot
  forward or backward a given distance (in cm) by calling
  <code>pilot.travel(distance)</code>.
</p>

<% partial 'partials/material_sub_heading' do %>
  Sensing
<% end %>

<p>
  The Mindstorms packages include touch, sound, light, and ultrasonic
  sensors. We need only the last two of these.
</p>

<p>
  A light sensor object is constructed by calling the constructor
  with the sensor port to which the sensor is connected as an argument.
  The object returns the lightness value sensed by the sensor
  with the method <code>readValue</code>.
</p>

<% partial 'partials/code_highlight' do %>
LightSensor light = new LightSensor(SensorPort.S2);
int l = light.readValue();
<% end %>

<p>
  Note that the lightness value depends on the lighting conditions, and
  in practice it is best to "calibrate" it manually by simply
  printing out values from the sensor on the robot display. It is
  okay to hard-code a threshold that detects light vs dark objects
  in your code.
</p>

<p>
  An ultrasonic sensor can be constructed similarly. Remember to check
  the correct sensor port by following the cable connecting the sensor
  to the main brick.
</p>

<% partial 'partials/code_highlight' do %>
UltraSonicSensor sonic = new UltraSonicSensor(SensorPort.S3);
int d = sonic.getDistance()  // 0-255 (cm)
<% end %>

<p>
  If no echo is caught, the reading wll be 255.
</p>
