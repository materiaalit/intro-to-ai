---
  title: Part 6
  exercise_page: true
  quiz_page: false
  published: true
---

<% partial 'partials/material_heading' do %>
  Ethics in AI
<% end %>

<p>
One day you'll end up in a heated conversation on twitter. It started with a university professor's
(@TuringLives) tweet on photo recreation models. He told about a model developed in his lab. The
model depixelated an input image of Finnish Prime Minister Sanna Marin into a photo of middle-
aged white male:
<br>
<img width=80% src="/img/ex6_1.png">
<br>
</p>

<% partial 'partials/exercise', locals: { name: 'Generative Adversarial Networks (1p)' } do %>
<p>
The face upsampling was made by using GANs. To see how GANs work, check out <a href="https://gandissect.csail.mit.edu/">this</a> website.
Try out the associated applet on <a href="http://gandissect.res.ibm.com/ganpaint.html">here</a> and save the three best pictures you create.
</p>

<% end %>

<p>
The Twitter debate proceeds as follows:
</p>

<p>
@TuringLives: “Contemporary “face upsampling” systems just do this. If one trains
algorithms with images of white males, algorithms produce images of white males.
That's how they work.
</p>

<p>
@AdaLovelace: “ This is an example of about something more important: The hidden dangers of our algorithms.
The hidden biases of our algorithms. Would you
want algorithms like these to decide, who gets a job, gets arrested or passes the security check in the airports? I don't. ”
</p>

<p>
@Turinglives: “That's how these systems work, guys.
These algorithms produce biased results, if they are trained with biased data.
Face upsampling systems make everyone look white males, if they are trained with the datasets of white males.”
</p>

<p>
@EugeneG: “But that's not the problem, man. It really isn't about datasets, it is
about the whole machine learning industry. Don't reduce harms caused by this industry to dataset bias.”
</p>

<p>
@Turinglives: “Well, I didn't. All I say:
If we use biased datasets, then we'll have biased results.
That's why researchers need to be more careful selecting their data so
that they don't accidentally encode biases like this.
And, it is one thing to do research, and an another thing to deploy these methods in real world applications.
One should worry about bias in practical applications, not bias in academic research.”
</p>

<p>
@Gödel'sGhost: “Users get their applications from the engineers, the engineers get
their methods from computer scientists.
At least computer scientists should recognize how biased their methods are. And tell it.”
</p>

<p>
@Turinglives: “Yes, I agree. But isn't it one thing to do research on these things, and
another to deploy them in practice?
The consequences of bias are more problematic, when they are in a deployed product than in an academic paper.
Don ́t bark the wrong tree.”
</p>

<p>
@TheManIntheChineseRoom: “So, you basically say: Researchers might
acknowledge their data is biased, use it anyway because it's there, and then 
say ”it's acceptable because it is just an academic experiment and I am not
responsible, ifsomeone uses it in a way that causes harm? Is that your answer?”
</p>

<p>
@Turinglives: ”Well, yes and no. Isn't there a difference between basic 
research and using applications in real world tasks? 
Think about physicists. Are physicists responsible for nuclear weaponry?
Or, are biologists studying genes responsible for eugenetics?
Isn't this precisely the same question? Can we judge basic research, because
there can be bad applications? And still, I acknowledge, bias is a big concern, but for
the real world applications.”
</p>

<p>
@YourReply:”...”?
</p>


<% partial 'partials/exercise', locals: { name: 'Tweet! (1p)' } do %>

Now, you'll join into the discussion. How would you respond to these tweets?
Please, reply by a “tweet”. Pick a twitter name, and write a reply.

<% end %>



<% partial 'partials/exercise', locals: { name: 'Essay (2p)' } do %>

What is this discussion about? What are the ethical issues? Do you see
them as significant? Please, analyse the discussion and individuate ethical
themes.
Write a short (150-300 words) essay, in which you estimate the importance of these topics for a student of computer or data sciences.

Please submit your essay as a single pdf file to the teaching assistant
(<a href="mailto:jarkko.savela@helsinki.fi">jarkko.savela@helsinki.fi</a>
or <a href="mailto:matti.leinonen@helsinki.fi">matti.leinonen@helsinki.fi</a>) 
of the exercise group you will attend before the exercise session.

<% end %>


<% partial 'partials/exercise', locals: { name: 'Feedback (2p)' } do %>

<p>
  The development of this course relies on your feedback. To give you
  a concrete incentive to give feedback, you'll even get exercise
  points for giving feedback!
</p>

<p>
  The deadline for this exercise is November 1 (one week after the
  course exam).
</p>

<p>
  Give feedback in both of the following ways:
  <ol>
    <li>
      First, submit anonymously through the university feedback
      system. You can find the feedback form in WebOodi.
    <li>
      <b>After you have submitted the anonymous feedback</b>, send
	email to the
	lecturer: <a href="mailto:teemu.roos@cs.helsinki.fi">
	teemu.roos@cs.helsinki.fi</a>. <b>Important:</b> Include 
        the magic word IntroAI2020 on the subject line so that Teemu
        will find your message in his inbox among 5615 unread messages.
  </ol>
</p>

<p>
  To get 1p for item 1, mention in your email that you have submitted
  the anonymous feedback through the feedback system &mdash; after actually
  doing so, of course.
</p>

<p>
  Also give feedback in the email. You can summarize your anonymous
  feeback briefly. Don't worry if the content is overlapping.
</p>

<% end %>

You can find the lecture slides for this part on the <a href="https://courses.helsinki.fi/en/data15001/129802916">course homepage</a>
under Materials.
